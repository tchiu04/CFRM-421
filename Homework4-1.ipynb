{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>CFRM 421/521</center>\n",
    "</h1>\n",
    "\n",
    "<h1>\n",
    "<center>Terence Chiu</center>\n",
    "</h1>\n",
    "\n",
    "<h1>\n",
    "<center>Homework 4</center>\n",
    "</h1>\n",
    "\n",
    "* **Due: Tuesday, May 27, 2025, 11:59 PM**\n",
    "\n",
    "\n",
    "* Total marks: 43\n",
    "\n",
    "\n",
    "* Late submissions are allowed, but a 20% penalty per day applies. Your last submission is considered for calculating the penalty.\n",
    "\n",
    "\n",
    "*  Use this Jupyter notebook as a template for your solutions. **Your solution must be submitted as both one Jupyter notebook and one PDF file on Gradescope.** There will be two modules on Gradescope, one for each file type. The notebook must be already run, that is, make sure that you have run all the code, save the notebook, and then when you reopen the notebook, checked that all output appears as expected. You are allowed to use code from the textbook, textbook website, or lecture notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A regression MLP [12 marks]\n",
    "\n",
    "Consider the original source of the California housing data (used in Homework 2) in Scikit-Learn.  The data is obtained and split using the code below, where we split off 20% as the test set, and then split off 20% of the training set as a validation set, and keep the remaining 80% of the training set as the actual training set. The following code creates the training set `X_train`, `y_train`, the validation set `X_valid`, `y_valid` and the test set `X_test`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "X_train_tmp, X_test, y_train_tmp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_tmp, y_train_tmp, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [4 marks]\n",
    "\n",
    "Use `tensorflow.keras` to train a regression MLP with a normalization layer as the first layer (`tf.keras.layers.Normalization(input_shape=X_train.shape[1:])`), and one hidden layer of 50 ReLU neurons. For the output layer, try both a ReLU activation function and no activation function (which is equivalent to the identity function). Explain which choice is better. Use the appropriate weight initialization. Use the Nadam optimizer. Train for 30 epochs, and report the mean squared error on the validation set. In the `.compile()` method, use `loss=\"mse\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "X_valid_flattened = X_valid.reshape(X_valid.shape[0], -1)\n",
    "\n",
    "mlp_non = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train_flattened.shape[1:]),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "mlp_non.compile(loss=\"mse\", optimizer=\"Nadam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.7566\n",
      "Epoch 2/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 4.6450\n",
      "Epoch 3/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.2868\n",
      "Epoch 4/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.0674\n",
      "Epoch 5/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.3742\n",
      "Epoch 6/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.7332\n",
      "Epoch 7/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.2651\n",
      "Epoch 8/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.6757\n",
      "Epoch 9/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 26.3847\n",
      "Epoch 10/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.1730\n",
      "Epoch 11/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 6.8736\n",
      "Epoch 12/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.6087\n",
      "Epoch 13/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.1741\n",
      "Epoch 14/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 18.6088\n",
      "Epoch 15/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8607\n",
      "Epoch 16/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2.0432\n",
      "Epoch 17/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.5754\n",
      "Epoch 18/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.3024\n",
      "Epoch 19/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.2282\n",
      "Epoch 20/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 4.1139\n",
      "Epoch 21/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.7156\n",
      "Epoch 22/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 11.1443\n",
      "Epoch 23/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 16.0731\n",
      "Epoch 24/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.4222\n",
      "Epoch 25/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 13.5743\n",
      "Epoch 26/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.3263\n",
      "Epoch 27/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2.1129\n",
      "Epoch 28/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.2483\n",
      "Epoch 29/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 13.0094\n",
      "Epoch 30/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 64.1702\n",
      "CPU times: user 1min 23s, sys: 1min 1s, total: 2min 24s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x325a6f450>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time mlp_non.fit(X_train_flattened, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8380\n",
      "Validation MSE: 0.8447631597518921\n"
     ]
    }
   ],
   "source": [
    "val_mse = mlp_non.evaluate(X_valid_flattened, y_valid)\n",
    "print(f\"Validation MSE: {val_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "mlp_relu = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train_flattened.shape[1:]),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "mlp_relu.compile(loss=\"mse\", optimizer=\"Nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 17.2520\n",
      "Epoch 2/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5060\n",
      "Epoch 3/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5532\n",
      "Epoch 4/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5279\n",
      "Epoch 5/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6102\n",
      "Epoch 6/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.4817\n",
      "Epoch 7/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.4536\n",
      "Epoch 8/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6263\n",
      "Epoch 9/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6653\n",
      "Epoch 10/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6840\n",
      "Epoch 11/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 5.5953\n",
      "Epoch 12/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5892\n",
      "Epoch 13/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 5.5575\n",
      "Epoch 14/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 5.6013\n",
      "Epoch 15/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6885\n",
      "Epoch 16/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5011\n",
      "Epoch 17/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6245\n",
      "Epoch 18/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5653\n",
      "Epoch 19/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6470\n",
      "Epoch 20/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.4966\n",
      "Epoch 21/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5571\n",
      "Epoch 22/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 5.6223\n",
      "Epoch 23/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5345\n",
      "Epoch 24/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6515\n",
      "Epoch 25/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6351\n",
      "Epoch 26/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5586\n",
      "Epoch 27/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5330\n",
      "Epoch 28/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6203\n",
      "Epoch 29/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6463\n",
      "Epoch 30/30\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6418\n",
      "CPU times: user 1min 23s, sys: 1min 3s, total: 2min 26s\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x376da1510>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time mlp_relu.fit(X_train_flattened, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8433\n",
      "Validation MSE: 5.756706237792969\n"
     ]
    }
   ],
   "source": [
    "val_mse = mlp_relu.evaluate(X_valid_flattened, y_valid)\n",
    "print(f\"Validation MSE: {val_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [6 marks]\n",
    "\n",
    "Read the section \"Fine-Tuning Neural Network Hyperparameters\" in the textbook and the corresponding section in the [Jupyter notebook](https://github.com/ageron/handson-ml3/blob/main/10_neural_nets_with_keras.ipynb) on the textbook website using Keras Tuner. You will need to install the package `keras_tuner` if you don't already have it.\n",
    "\n",
    "Then use Keras Tuner to do a randomized search to search for the best hyperparameters. Do the randomized search over the first 5000 observations of the training set. Use 20 iterations, 20 epochs per iteration. Use the same network architecture as (a) except where otherwise specified below. Use no activation function for the output layer. Use a seed of 42, and the objective is clearly to minimize validation loss. The hyperparameters to search over are:\n",
    "\n",
    "* Hidden layers: 1 to 5.\n",
    "* Number of neurons per layer: 1 to 100.\n",
    "* Learning rate: 1e-4 to 1e-2 using log sampling.\n",
    "* $\\ell_2$ regularizers with `l2` value: 1e-4 to 100 using log sampling.\n",
    "* Optimizer: `tf.keras.optimizers.SGD(learning_rate=learning_rate,clipnorm=1.0)` and `tf.keras.optimizers.Nadam(learning_rate=learning_rate)`.\n",
    "\n",
    "Print the best hyperparameter. (You can ignore any warning message you may get)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train[:5000], y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=1, max_value=5)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=1, max_value=200)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "                             sampling=\"log\")\n",
    "    \n",
    "    l2_reg = hp.Float(\"l2_reg\", min_value=1e-4, max_value=100,\n",
    "                             sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"nadam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, clipnorm = 1.0)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Normalization(input_shape=X_train.shape[1:]))\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "                    n_neurons, \n",
    "                    activation=\"relu\",\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "        ))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 25s]\n",
      "val_loss: 29.931848526000977\n",
      "\n",
      "Best val_loss So Far: 0.7406060695648193\n",
      "Total elapsed time: 00h 09m 24s\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, objective=\"val_loss\", max_trials=20, overwrite=True,\n",
    "    directory=\"my_california_housing\", project_name=\"my_rnd_search\", seed=42)\n",
    "random_search_tuner.search(X_train, y_train, epochs=20,\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 2 variables whereas the saved optimizer has 11 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m)             │           \u001b[38;5;34m648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m73\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">738</span> (2.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m738\u001b[0m (2.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">721</span> (2.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m721\u001b[0m (2.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (72.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17\u001b[0m (72.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 11.1591\n",
      "Epoch 2/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6924\n",
      "Epoch 3/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9928\n",
      "Epoch 4/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0400\n",
      "Epoch 5/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0115\n",
      "Epoch 6/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.9734\n",
      "Epoch 7/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0850\n",
      "Epoch 8/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7065\n",
      "Epoch 9/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9485\n",
      "Epoch 10/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1451\n",
      "Epoch 11/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.8858\n",
      "Epoch 12/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1763\n",
      "Epoch 13/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.3416\n",
      "Epoch 14/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.3957\n",
      "Epoch 15/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1999\n",
      "Epoch 16/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8410\n",
      "Epoch 17/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.1466\n",
      "Epoch 18/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2430\n",
      "Epoch 19/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1124\n",
      "Epoch 20/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3241\n",
      "Epoch 21/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9711\n",
      "Epoch 22/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.7305\n",
      "Epoch 23/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0616\n",
      "Epoch 24/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.3725\n",
      "Epoch 25/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1023\n",
      "Epoch 26/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.8542\n",
      "Epoch 27/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8496\n",
      "Epoch 28/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9234\n",
      "Epoch 29/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9834\n",
      "Epoch 30/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.0835\n",
      "Epoch 31/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3471\n",
      "Epoch 32/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.9699\n",
      "Epoch 33/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.5276\n",
      "Epoch 34/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.1602\n",
      "Epoch 35/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9104\n",
      "Epoch 36/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.7542\n",
      "Epoch 37/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.0429\n",
      "Epoch 38/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8996\n",
      "Epoch 39/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2182\n",
      "Epoch 40/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.5125\n",
      "Epoch 41/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1908\n",
      "Epoch 42/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.0446\n",
      "Epoch 43/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.2266\n",
      "Epoch 44/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4383\n",
      "Epoch 45/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2955\n",
      "Epoch 46/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.1273\n",
      "Epoch 47/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4814\n",
      "Epoch 48/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.2476\n",
      "Epoch 49/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7626\n",
      "Epoch 50/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.4062\n",
      "Epoch 51/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.0525\n",
      "Epoch 52/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7075\n",
      "Epoch 53/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0004\n",
      "Epoch 54/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0634\n",
      "Epoch 55/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0972\n",
      "Epoch 56/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.7249\n",
      "Epoch 57/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 10.8000\n",
      "Epoch 58/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7024\n",
      "Epoch 59/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7322\n",
      "Epoch 60/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7672\n",
      "Epoch 61/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0413\n",
      "Epoch 62/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8825\n",
      "Epoch 63/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0670\n",
      "Epoch 64/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9333\n",
      "Epoch 65/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1990\n",
      "Epoch 66/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6177\n",
      "Epoch 67/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5814\n",
      "Epoch 68/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5032\n",
      "Epoch 69/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.3121\n",
      "Epoch 70/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1010\n",
      "Epoch 71/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.3373\n",
      "Epoch 72/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1529\n",
      "Epoch 73/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.5072\n",
      "Epoch 74/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.5117\n",
      "Epoch 75/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8170\n",
      "Epoch 76/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1216\n",
      "Epoch 77/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1105\n",
      "Epoch 78/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4006\n",
      "Epoch 79/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7606\n",
      "Epoch 80/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.1327\n",
      "Epoch 81/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.4018\n",
      "Epoch 82/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.4434\n",
      "Epoch 83/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9957\n",
      "Epoch 84/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7033\n",
      "Epoch 85/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11.5669\n",
      "Epoch 86/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 18.4673\n",
      "Epoch 87/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8657\n",
      "Epoch 88/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7441\n",
      "Epoch 89/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6868\n",
      "Epoch 90/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7345\n",
      "Epoch 91/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0674\n",
      "Epoch 92/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7257\n",
      "Epoch 93/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9777\n",
      "Epoch 94/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9778\n",
      "Epoch 95/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.4493\n",
      "Epoch 96/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3108\n",
      "Epoch 97/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4366\n",
      "Epoch 98/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3855\n",
      "Epoch 99/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 20.3921\n",
      "Epoch 100/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7375\n",
      "Epoch 101/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8267\n",
      "Epoch 102/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1423\n",
      "Epoch 103/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9944\n",
      "Epoch 104/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0868\n",
      "Epoch 105/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4353\n",
      "Epoch 106/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9997\n",
      "Epoch 107/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3665\n",
      "Epoch 108/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.8998\n",
      "Epoch 109/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8250\n",
      "Epoch 110/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.6029\n",
      "Epoch 111/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5359\n",
      "Epoch 112/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.5374\n",
      "Epoch 113/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2458\n",
      "Epoch 114/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.5195\n",
      "Epoch 115/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.2383\n",
      "Epoch 116/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7358\n",
      "Epoch 117/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3160\n",
      "Epoch 118/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6975\n",
      "Epoch 119/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6143\n",
      "Epoch 120/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.5965\n",
      "Epoch 121/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4884\n",
      "Epoch 122/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.4717\n",
      "Epoch 123/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9938\n",
      "Epoch 124/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.0621\n",
      "Epoch 125/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6351\n",
      "Epoch 126/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9281\n",
      "Epoch 127/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8936\n",
      "Epoch 128/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.4317\n",
      "Epoch 129/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.6529\n",
      "Epoch 130/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.5998\n",
      "Epoch 131/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9026\n",
      "Epoch 132/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.7154\n",
      "Epoch 133/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.2931\n",
      "Epoch 134/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5740\n",
      "Epoch 135/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.3051\n",
      "Epoch 136/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.3923\n",
      "Epoch 137/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1209\n",
      "Epoch 138/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.9915\n",
      "Epoch 139/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.1510\n",
      "Epoch 140/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8043\n",
      "Epoch 141/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1443\n",
      "Epoch 142/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1273\n",
      "Epoch 143/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11.5340\n",
      "Epoch 144/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4056\n",
      "Epoch 145/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1423\n",
      "Epoch 146/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.0019\n",
      "Epoch 147/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.4951\n",
      "Epoch 148/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6066\n",
      "Epoch 149/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0860\n",
      "Epoch 150/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.5123\n",
      "Epoch 151/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4254\n",
      "Epoch 152/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.6158\n",
      "Epoch 153/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8309\n",
      "Epoch 154/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4312\n",
      "Epoch 155/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1655\n",
      "Epoch 156/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0724\n",
      "Epoch 157/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.5167\n",
      "Epoch 158/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0100\n",
      "Epoch 159/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0653\n",
      "Epoch 160/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4465\n",
      "Epoch 161/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7565\n",
      "Epoch 162/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.2831\n",
      "Epoch 163/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1182\n",
      "Epoch 164/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.0763\n",
      "Epoch 165/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5845\n",
      "Epoch 166/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.7451\n",
      "Epoch 167/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8874\n",
      "Epoch 168/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0021\n",
      "Epoch 169/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0103\n",
      "Epoch 170/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8795\n",
      "Epoch 171/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0049\n",
      "Epoch 172/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.5462\n",
      "Epoch 173/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.3018\n",
      "Epoch 174/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 16.4861\n",
      "Epoch 175/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3927\n",
      "Epoch 176/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1063\n",
      "Epoch 177/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.5215\n",
      "Epoch 178/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0166\n",
      "Epoch 179/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1967\n",
      "Epoch 180/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.2583\n",
      "Epoch 181/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2945\n",
      "Epoch 182/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9575\n",
      "Epoch 183/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.5504\n",
      "Epoch 184/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5303\n",
      "Epoch 185/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.2048\n",
      "Epoch 186/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9036\n",
      "Epoch 187/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 22.2856\n",
      "Epoch 188/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.8053\n",
      "Epoch 189/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.7708\n",
      "Epoch 190/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0316\n",
      "Epoch 191/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.2456\n",
      "Epoch 192/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0214\n",
      "Epoch 193/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6742\n",
      "Epoch 194/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.5322\n",
      "Epoch 195/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7232\n",
      "Epoch 196/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1141\n",
      "Epoch 197/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2666\n",
      "Epoch 198/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1592\n",
      "Epoch 199/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.2197\n",
      "Epoch 200/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.4604\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4086\n",
      "Validation MSE: 5.484653472900391\n"
     ]
    }
   ],
   "source": [
    "top_model = random_search_tuner.get_best_models(num_models=1)\n",
    "best_model = top_model[0]\n",
    "best_model.summary()\n",
    "best_model.fit(X_train, y_train, epochs=200)\n",
    "val_mse = best_model.evaluate(X_valid, y_valid)\n",
    "print(f\"Validation MSE: {val_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 1,\n",
       " 'n_neurons': 72,\n",
       " 'learning_rate': 0.0006426228293037218,\n",
       " 'l2_reg': 0.0007481962559686448,\n",
       " 'optimizer': 'nadam'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_params = random_search_tuner.get_best_hyperparameters(num_trials=1)\n",
    "top_params[0].values  # best hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) [2 marks]\n",
    "\n",
    "For the best model in (b), train the model on the full training data for 200 epochs. Plot the learning curve. Does it look like the model is overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.2831 - val_loss: 17.9176\n",
      "Epoch 2/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.2240 - val_loss: 0.7408\n",
      "Epoch 3/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 15.2895 - val_loss: 0.8214\n",
      "Epoch 4/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7067 - val_loss: 0.7492\n",
      "Epoch 5/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8319 - val_loss: 2.0148\n",
      "Epoch 6/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5989 - val_loss: 0.8412\n",
      "Epoch 7/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 15.0521 - val_loss: 0.8589\n",
      "Epoch 8/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8218 - val_loss: 0.8037\n",
      "Epoch 9/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8690 - val_loss: 0.8580\n",
      "Epoch 10/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9219 - val_loss: 1.3060\n",
      "Epoch 11/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3477 - val_loss: 0.8842\n",
      "Epoch 12/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7826 - val_loss: 0.8110\n",
      "Epoch 13/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.2994 - val_loss: 0.9235\n",
      "Epoch 14/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.0496 - val_loss: 1.9467\n",
      "Epoch 15/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.0157 - val_loss: 1.5300\n",
      "Epoch 16/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0806 - val_loss: 0.9516\n",
      "Epoch 17/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4597 - val_loss: 2.1113\n",
      "Epoch 18/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7017 - val_loss: 6.8797\n",
      "Epoch 19/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.9990 - val_loss: 1.3288\n",
      "Epoch 20/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1949 - val_loss: 1.0468\n",
      "Epoch 21/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2168 - val_loss: 1.1964\n",
      "Epoch 22/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.8642 - val_loss: 1.2966\n",
      "Epoch 23/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.8458 - val_loss: 2.0292\n",
      "Epoch 24/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.9492 - val_loss: 1.1300\n",
      "Epoch 25/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7835 - val_loss: 3.9282\n",
      "Epoch 26/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.9136 - val_loss: 50.4222\n",
      "Epoch 27/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.2471 - val_loss: 3.1518\n",
      "Epoch 28/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.9000 - val_loss: 1.0248\n",
      "Epoch 29/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9259 - val_loss: 0.8390\n",
      "Epoch 30/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8623 - val_loss: 0.7235\n",
      "Epoch 31/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2206 - val_loss: 1.2249\n",
      "Epoch 32/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.1865 - val_loss: 1.2787\n",
      "Epoch 33/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 13.5425 - val_loss: 1.2310\n",
      "Epoch 34/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8136 - val_loss: 0.7534\n",
      "Epoch 35/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8308 - val_loss: 0.7893\n",
      "Epoch 36/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8668 - val_loss: 5.3353\n",
      "Epoch 37/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9850 - val_loss: 1.3301\n",
      "Epoch 38/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8611 - val_loss: 0.9412\n",
      "Epoch 39/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8313 - val_loss: 3.5037\n",
      "Epoch 40/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3662 - val_loss: 1.2102\n",
      "Epoch 41/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6381 - val_loss: 1.4338\n",
      "Epoch 42/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.3976 - val_loss: 1.5627\n",
      "Epoch 43/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7965 - val_loss: 0.8909\n",
      "Epoch 44/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.1082 - val_loss: 2.4214\n",
      "Epoch 45/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.2003 - val_loss: 4.0875\n",
      "Epoch 46/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.0024 - val_loss: 1.6884\n",
      "Epoch 47/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0369 - val_loss: 0.7181\n",
      "Epoch 48/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7894 - val_loss: 0.8649\n",
      "Epoch 49/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9815 - val_loss: 10.5462\n",
      "Epoch 50/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2703 - val_loss: 2.1239\n",
      "Epoch 51/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4887 - val_loss: 1.4032\n",
      "Epoch 52/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.3969 - val_loss: 1.1514\n",
      "Epoch 53/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8072 - val_loss: 1.7844\n",
      "Epoch 54/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0673 - val_loss: 0.8206\n",
      "Epoch 55/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0938 - val_loss: 1.2686\n",
      "Epoch 56/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0978 - val_loss: 0.8705\n",
      "Epoch 57/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6450 - val_loss: 1.0597\n",
      "Epoch 58/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.2824 - val_loss: 2.6052\n",
      "Epoch 59/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.5973 - val_loss: 2.8481\n",
      "Epoch 60/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9249 - val_loss: 1.1958\n",
      "Epoch 61/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6714 - val_loss: 0.9349\n",
      "Epoch 62/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7710 - val_loss: 0.9138\n",
      "Epoch 63/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 11.2271 - val_loss: 0.8950\n",
      "Epoch 64/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8291 - val_loss: 0.8258\n",
      "Epoch 65/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8167 - val_loss: 1.9749\n",
      "Epoch 66/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9479 - val_loss: 1.0702\n",
      "Epoch 67/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8657 - val_loss: 2.2689\n",
      "Epoch 68/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4863 - val_loss: 1.2572\n",
      "Epoch 69/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4360 - val_loss: 1.6645\n",
      "Epoch 70/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0886 - val_loss: 7.8021\n",
      "Epoch 71/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.3950 - val_loss: 1.2625\n",
      "Epoch 72/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6519 - val_loss: 2.2869\n",
      "Epoch 73/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.7571 - val_loss: 1.7718\n",
      "Epoch 74/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.9237 - val_loss: 4.5481\n",
      "Epoch 75/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1124 - val_loss: 2.3777\n",
      "Epoch 76/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.1451 - val_loss: 1.2160\n",
      "Epoch 77/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1432 - val_loss: 7.9961\n",
      "Epoch 78/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.9492 - val_loss: 2.5521\n",
      "Epoch 79/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 16.8641 - val_loss: 1.1583\n",
      "Epoch 80/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1275 - val_loss: 0.9948\n",
      "Epoch 81/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9005 - val_loss: 0.7458\n",
      "Epoch 82/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8172 - val_loss: 0.8136\n",
      "Epoch 83/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3591 - val_loss: 1.1930\n",
      "Epoch 84/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5514 - val_loss: 1.0374\n",
      "Epoch 85/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1652 - val_loss: 1.1017\n",
      "Epoch 86/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2726 - val_loss: 2.8101\n",
      "Epoch 87/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.7390 - val_loss: 1.0026\n",
      "Epoch 88/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.3457 - val_loss: 1.6182\n",
      "Epoch 89/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.8291 - val_loss: 19.4226\n",
      "Epoch 90/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.1945 - val_loss: 4.3184\n",
      "Epoch 91/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.3201 - val_loss: 1.2591\n",
      "Epoch 92/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.5982 - val_loss: 61.8622\n",
      "Epoch 93/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.0455 - val_loss: 2.1230\n",
      "Epoch 94/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.4178 - val_loss: 1.3618\n",
      "Epoch 95/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.8726 - val_loss: 2.2778\n",
      "Epoch 96/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3550 - val_loss: 6.0926\n",
      "Epoch 97/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 19.2627 - val_loss: 2.3940\n",
      "Epoch 98/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1893 - val_loss: 1.3291\n",
      "Epoch 99/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.8493 - val_loss: 2.5057\n",
      "Epoch 100/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7648 - val_loss: 0.8175\n",
      "Epoch 101/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.8709 - val_loss: 0.7723\n",
      "Epoch 102/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3318 - val_loss: 1.0051\n",
      "Epoch 103/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9272 - val_loss: 0.9237\n",
      "Epoch 104/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3375 - val_loss: 4.0007\n",
      "Epoch 105/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2223 - val_loss: 1.8088\n",
      "Epoch 106/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.2175 - val_loss: 22.7076\n",
      "Epoch 107/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.7975 - val_loss: 0.8109\n",
      "Epoch 108/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.7120 - val_loss: 1.5496\n",
      "Epoch 109/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6049 - val_loss: 11.5184\n",
      "Epoch 110/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.4399 - val_loss: 1.2472\n",
      "Epoch 111/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4970 - val_loss: 4.8085\n",
      "Epoch 112/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.2549 - val_loss: 0.9772\n",
      "Epoch 113/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9760 - val_loss: 3.5631\n",
      "Epoch 114/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.6914 - val_loss: 10.3235\n",
      "Epoch 115/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.6378 - val_loss: 1.8845\n",
      "Epoch 116/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5377 - val_loss: 1.6519\n",
      "Epoch 117/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9591 - val_loss: 0.8615\n",
      "Epoch 118/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7835 - val_loss: 0.8091\n",
      "Epoch 119/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1523 - val_loss: 16.2491\n",
      "Epoch 120/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.8071 - val_loss: 0.8072\n",
      "Epoch 121/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4125 - val_loss: 1.0169\n",
      "Epoch 122/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.2686 - val_loss: 0.7785\n",
      "Epoch 123/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.2639 - val_loss: 11.1052\n",
      "Epoch 124/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.3535 - val_loss: 2.6842\n",
      "Epoch 125/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.7804 - val_loss: 1.4287\n",
      "Epoch 126/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7671 - val_loss: 0.8142\n",
      "Epoch 127/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4645 - val_loss: 1.0581\n",
      "Epoch 128/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.4654 - val_loss: 1.6524\n",
      "Epoch 129/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.3612 - val_loss: 2.5185\n",
      "Epoch 130/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1904 - val_loss: 0.8724\n",
      "Epoch 131/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9897 - val_loss: 55.3810\n",
      "Epoch 132/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.9254 - val_loss: 1.5071\n",
      "Epoch 133/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.9385 - val_loss: 0.7927\n",
      "Epoch 134/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.1582 - val_loss: 1.9747\n",
      "Epoch 135/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.6295 - val_loss: 1.4641\n",
      "Epoch 136/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.1936 - val_loss: 4.7513\n",
      "Epoch 137/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.5836 - val_loss: 1.0753\n",
      "Epoch 138/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8090 - val_loss: 6.5753\n",
      "Epoch 139/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.8573 - val_loss: 1.3106\n",
      "Epoch 140/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.8284 - val_loss: 1.1758\n",
      "Epoch 141/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.2072 - val_loss: 0.7729\n",
      "Epoch 142/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.2765 - val_loss: 8.8806\n",
      "Epoch 143/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7851 - val_loss: 1.1954\n",
      "Epoch 144/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6880 - val_loss: 2.9030\n",
      "Epoch 145/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7251 - val_loss: 1.2896\n",
      "Epoch 146/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.0094 - val_loss: 6.6918\n",
      "Epoch 147/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.5424 - val_loss: 35.3931\n",
      "Epoch 148/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.7520 - val_loss: 1.2206\n",
      "Epoch 149/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8934 - val_loss: 1.6168\n",
      "Epoch 150/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8992 - val_loss: 1.0315\n",
      "Epoch 151/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9779 - val_loss: 2.4303\n",
      "Epoch 152/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.8442 - val_loss: 1.8399\n",
      "Epoch 153/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3429 - val_loss: 2.8081\n",
      "Epoch 154/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.2056 - val_loss: 2.2157\n",
      "Epoch 155/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.8498 - val_loss: 1.0427\n",
      "Epoch 156/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1614 - val_loss: 1.0488\n",
      "Epoch 157/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2088 - val_loss: 1.4792\n",
      "Epoch 158/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7213 - val_loss: 1.2359\n",
      "Epoch 159/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.5858 - val_loss: 1.0460\n",
      "Epoch 160/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.5550 - val_loss: 1.3737\n",
      "Epoch 161/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.3016 - val_loss: 3.3746\n",
      "Epoch 162/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.2200 - val_loss: 1.5970\n",
      "Epoch 163/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.9530 - val_loss: 0.8410\n",
      "Epoch 164/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3294 - val_loss: 1.3286\n",
      "Epoch 165/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.4612 - val_loss: 23.6539\n",
      "Epoch 166/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.8501 - val_loss: 0.8760\n",
      "Epoch 167/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.5948 - val_loss: 1.1083\n",
      "Epoch 168/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5615 - val_loss: 2.4252\n",
      "Epoch 169/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.4345 - val_loss: 4.1999\n",
      "Epoch 170/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.0674 - val_loss: 2.8882\n",
      "Epoch 171/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2802 - val_loss: 104.3485\n",
      "Epoch 172/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 18.7047 - val_loss: 3.4474\n",
      "Epoch 173/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6659 - val_loss: 2.3177\n",
      "Epoch 174/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.5014 - val_loss: 1.4908\n",
      "Epoch 175/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4287 - val_loss: 2.6554\n",
      "Epoch 176/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4719 - val_loss: 18.4395\n",
      "Epoch 177/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.7078 - val_loss: 0.8466\n",
      "Epoch 178/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.7981 - val_loss: 1.0265\n",
      "Epoch 179/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2806 - val_loss: 3.2243\n",
      "Epoch 180/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4207 - val_loss: 5.9787\n",
      "Epoch 181/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 19.7492 - val_loss: 1.8888\n",
      "Epoch 182/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3117 - val_loss: 21.2742\n",
      "Epoch 183/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 12.6425 - val_loss: 1.3078\n",
      "Epoch 184/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0958 - val_loss: 1.5212\n",
      "Epoch 185/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.8835 - val_loss: 1.3586\n",
      "Epoch 186/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.6204 - val_loss: 12.6410\n",
      "Epoch 187/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 10.8148 - val_loss: 1.6484\n",
      "Epoch 188/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1825 - val_loss: 0.9205\n",
      "Epoch 189/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1561 - val_loss: 1.1265\n",
      "Epoch 190/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.7765 - val_loss: 1.0590\n",
      "Epoch 191/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9040 - val_loss: 0.8325\n",
      "Epoch 192/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9904 - val_loss: 0.8435\n",
      "Epoch 193/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5675 - val_loss: 2.1352\n",
      "Epoch 194/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.5306 - val_loss: 2.1328\n",
      "Epoch 195/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7849 - val_loss: 5.8454\n",
      "Epoch 196/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.4575 - val_loss: 4.3854\n",
      "Epoch 197/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.9598 - val_loss: 1.1862\n",
      "Epoch 198/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.5608 - val_loss: 1.1184\n",
      "Epoch 199/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 10.8337 - val_loss: 2.4177\n",
      "Epoch 200/200\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0407 - val_loss: 1.1235\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation loss: 1.1235\n"
     ]
    }
   ],
   "source": [
    "# Plot the learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print final validation loss\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "print(f\"Final validation loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Binary classification DNN [17 marks]\n",
    "\n",
    "Consider the [Portuguese Bank Marketing Data Set](https://www.kaggle.com/yufengsui/portuguese-bank-marketing-data-set?select=bank_cleaned.csv) available at Kaggle. Download the `bank_cleaned.csv` file or from [Canvas](https://canvas.uw.edu/files/106328167/download?download_frd=1). Here we want to predict the success or failure of a bank marketing campaign using phone calls to promote a term deposit product. The target variable is `response_binary`.\n",
    "\n",
    "The following code preprocesses the data. The day and month have been converted into cyclical features(1st day of the month has equal distance to the 2nd and the 31st)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/xcbt_9650nz8tknq733z87640000gn/T/ipykernel_16890/648047190.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  month_rad = (df[\"month\"].replace(month_dict) - 1) * (2 * np.pi / 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>response_binary</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0.724793</td>\n",
       "      <td>0.688967</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.52</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0.724793</td>\n",
       "      <td>0.688967</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0.724793</td>\n",
       "      <td>0.688967</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>231</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0.724793</td>\n",
       "      <td>0.688967</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>447</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0.724793</td>\n",
       "      <td>0.688967</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   35    management  married   tertiary      no      231     yes   no   \n",
       "4   28    management   single   tertiary      no      447     yes  yes   \n",
       "\n",
       "   duration  campaign  pdays  previous poutcome  response_binary   day_sin  \\\n",
       "0      4.35         1     -1         0  unknown                0  0.724793   \n",
       "1      2.52         1     -1         0  unknown                0  0.724793   \n",
       "2      1.27         1     -1         0  unknown                0  0.724793   \n",
       "3      2.32         1     -1         0  unknown                0  0.724793   \n",
       "4      3.62         1     -1         0  unknown                0  0.724793   \n",
       "\n",
       "    day_cos  month_sin  month_cos  \n",
       "0  0.688967   0.866025       -0.5  \n",
       "1  0.688967   0.866025       -0.5  \n",
       "2  0.688967   0.866025       -0.5  \n",
       "3  0.688967   0.866025       -0.5  \n",
       "4  0.688967   0.866025       -0.5  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bank_cleaned.csv\")\n",
    "\n",
    "month_dict = {\"jan\": 1, \"feb\": 2, \"mar\": 3, \"apr\": 4, \"may\": 5, \"jun\": 6,\n",
    "              \"jul\": 7, \"aug\": 8, \"sep\": 9, \"oct\": 10, \"nov\": 11, \"dec\": 12}\n",
    "day_rad = (df[\"day\"] - 1) * (2 * np.pi / 31)\n",
    "month_rad = (df[\"month\"].replace(month_dict) - 1) * (2 * np.pi / 12)\n",
    "df[\"day_sin\"] = np.sin(day_rad)\n",
    "df[\"day_cos\"] = np.cos(day_rad)\n",
    "df[\"month_sin\"] = np.sin(month_rad)\n",
    "df[\"month_cos\"]  = np.cos(month_rad)\n",
    "df.drop(columns=[\"Unnamed: 0\", \"month\", \"day\", \"response\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "train_set_tmp, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_set, valid_set = train_test_split(train_set_tmp, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_raw = train_set.drop(\"response_binary\", axis=1).copy()\n",
    "y_train = train_set[\"response_binary\"].copy()\n",
    "X_valid_raw = valid_set.drop(\"response_binary\", axis=1).copy()\n",
    "y_valid = valid_set[\"response_binary\"].copy()\n",
    "X_test_raw = test_set.drop(\"response_binary\", axis=1).copy()\n",
    "y_test = test_set[\"response_binary\"].copy()\n",
    "\n",
    "num_attribs = list(X_train_raw._get_numeric_data().columns)\n",
    "cat_attribs = list(set(X_train_raw.columns) - set(num_attribs))\n",
    "\n",
    "cat_attribs_ord = ['default', 'housing', 'loan']\n",
    "cat_attribs_hot = ['job', 'marital', 'education', 'poutcome']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_attribs),\n",
    "        (\"cat_hot\", OneHotEncoder(), cat_attribs_hot),\n",
    "        (\"cat_ord\", OrdinalEncoder(categories=[['no','yes'],['no','yes'],['no','yes']]), cat_attribs_ord)\n",
    "    ])\n",
    "\n",
    "X_train = full_pipeline.fit_transform(X_train_raw)\n",
    "X_valid = full_pipeline.transform(X_valid_raw)\n",
    "X_test = full_pipeline.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [4 marks]\n",
    "\n",
    "In the next part you will build and fit a DNN with 4 hidden layers of 100 neurons each. Use the following specifications:\n",
    "\n",
    "(i) He initialization and the Swish activation function.\n",
    "\n",
    "(ii) The output layer has 1 neuron with sigmoid activation.\n",
    "\n",
    "(iii) Compile with `loss=\"binary_crossentropy\"` and  `metrics=[\"AUC\"]`.\n",
    "\n",
    "Explain why the choices (i), (ii), and (iii) are justified.\n",
    "\n",
    "Also, state the proportion of sucesses in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train.shape[1:]),\n",
    "])\n",
    "\n",
    "for _ in range(4):\n",
    "    model.add(tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"AUC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- He initialization prevents the vanishing/exploding gradient problem by scaling weights based on number of input neurons\n",
    "- Swish activation, which is x * sigmoid(x), is justified because it works better than ReLU by letting in small negative values. It is more smooth aand differentiable everywhere.\n",
    "\n",
    "- Since this is a binary classification problem, 1 neuron is justified using sigmoid since the output we need are between 0 and 1.\n",
    "- Binary crossentropy because this is the standard loss function for our purpose\n",
    "- AUC metric is used because we are evluating how the model can distinguish between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of successes in training data: 0.1117\n"
     ]
    }
   ],
   "source": [
    "proportion_success = y_train.mean()\n",
    "print(f\"Proportion of successes in training data: {proportion_success:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [3 marks]\n",
    "\n",
    "Train the model in (a) for 30 epochs and use exponential scheduling using the function below (`lr0=0.01`, `s=20`) and the NAG optimizer with `momentum=0.9`. Use a learning curve to comment on whether it is overfitting.\n",
    "\n",
    "At the start of fitting your model, run `reset_session()` given by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_session(seed=42):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "def exponential_decay(lr0, s):\n",
    "    return lambda epoch: lr0 * 0.1**(epoch / s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - AUC: 0.8279 - loss: 0.2757 - val_AUC: 0.9023 - val_loss: 0.2230 - learning_rate: 0.0100\n",
      "Epoch 2/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9092 - loss: 0.2166 - val_AUC: 0.9080 - val_loss: 0.2173 - learning_rate: 0.0089\n",
      "Epoch 3/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9150 - loss: 0.2108 - val_AUC: 0.9106 - val_loss: 0.2139 - learning_rate: 0.0079\n",
      "Epoch 4/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9188 - loss: 0.2070 - val_AUC: 0.9128 - val_loss: 0.2114 - learning_rate: 0.0071\n",
      "Epoch 5/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9217 - loss: 0.2039 - val_AUC: 0.9144 - val_loss: 0.2095 - learning_rate: 0.0063\n",
      "Epoch 6/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9242 - loss: 0.2012 - val_AUC: 0.9155 - val_loss: 0.2081 - learning_rate: 0.0056\n",
      "Epoch 7/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9265 - loss: 0.1988 - val_AUC: 0.9161 - val_loss: 0.2070 - learning_rate: 0.0050\n",
      "Epoch 8/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9283 - loss: 0.1967 - val_AUC: 0.9170 - val_loss: 0.2062 - learning_rate: 0.0045\n",
      "Epoch 9/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9300 - loss: 0.1947 - val_AUC: 0.9177 - val_loss: 0.2057 - learning_rate: 0.0040\n",
      "Epoch 10/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9316 - loss: 0.1929 - val_AUC: 0.9179 - val_loss: 0.2054 - learning_rate: 0.0035\n",
      "Epoch 11/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9328 - loss: 0.1913 - val_AUC: 0.9184 - val_loss: 0.2052 - learning_rate: 0.0032\n",
      "Epoch 12/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9341 - loss: 0.1898 - val_AUC: 0.9185 - val_loss: 0.2051 - learning_rate: 0.0028\n",
      "Epoch 13/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - AUC: 0.9352 - loss: 0.1884 - val_AUC: 0.9186 - val_loss: 0.2051 - learning_rate: 0.0025\n",
      "Epoch 14/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9361 - loss: 0.1871 - val_AUC: 0.9187 - val_loss: 0.2051 - learning_rate: 0.0022\n",
      "Epoch 15/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9371 - loss: 0.1860 - val_AUC: 0.9189 - val_loss: 0.2052 - learning_rate: 0.0020\n",
      "Epoch 16/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9379 - loss: 0.1849 - val_AUC: 0.9188 - val_loss: 0.2053 - learning_rate: 0.0018\n",
      "Epoch 17/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9386 - loss: 0.1839 - val_AUC: 0.9186 - val_loss: 0.2054 - learning_rate: 0.0016\n",
      "Epoch 18/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9393 - loss: 0.1830 - val_AUC: 0.9187 - val_loss: 0.2055 - learning_rate: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9400 - loss: 0.1821 - val_AUC: 0.9188 - val_loss: 0.2056 - learning_rate: 0.0013\n",
      "Epoch 20/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - AUC: 0.9405 - loss: 0.1814 - val_AUC: 0.9188 - val_loss: 0.2058 - learning_rate: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9410 - loss: 0.1807 - val_AUC: 0.9190 - val_loss: 0.2059 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9414 - loss: 0.1800 - val_AUC: 0.9186 - val_loss: 0.2060 - learning_rate: 8.9125e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9418 - loss: 0.1794 - val_AUC: 0.9179 - val_loss: 0.2061 - learning_rate: 7.9433e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9422 - loss: 0.1788 - val_AUC: 0.9180 - val_loss: 0.2063 - learning_rate: 7.0795e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9425 - loss: 0.1783 - val_AUC: 0.9181 - val_loss: 0.2064 - learning_rate: 6.3096e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9428 - loss: 0.1779 - val_AUC: 0.9177 - val_loss: 0.2065 - learning_rate: 5.6234e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9432 - loss: 0.1774 - val_AUC: 0.9177 - val_loss: 0.2067 - learning_rate: 5.0119e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9434 - loss: 0.1771 - val_AUC: 0.9178 - val_loss: 0.2068 - learning_rate: 4.4668e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.9436 - loss: 0.1767 - val_AUC: 0.9178 - val_loss: 0.2069 - learning_rate: 3.9811e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - AUC: 0.9438 - loss: 0.1764 - val_AUC: 0.9177 - val_loss: 0.2070 - learning_rate: 3.5481e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reset_session()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train.shape[1:]),\n",
    "])\n",
    "\n",
    "for _ in range(4):\n",
    "    model.add(tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer=\"he_normal\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.9,\n",
    "    nesterov=True\n",
    ")\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"AUC\"])\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    exponential_decay(0.01, 20)\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[lr_scheduler])\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since validation loss starts increasing while training loss continues decreasing, this indicates overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) [8 marks]\n",
    "\n",
    "Fit separate models using the same specification as in (b) but with the following regularization techniques:\n",
    "\n",
    "(i) batch normalization,\n",
    "\n",
    "(ii) early stopping based on validation AUC with `patience=10` (look at the documentation and note the `mode` argument).\n",
    "\n",
    "(iii) $\\ell_2$ regularization with `l2=0.0002`,\n",
    "\n",
    "(iv) dropout with probability 0.02,\n",
    "\n",
    "(v) $\\ell_2$ regularization and early stopping both as above,\n",
    "\n",
    "(vi) batch normalization and dropout both as above.\n",
    "\n",
    "At the start of each one of the above models, run `reset_session()`.\n",
    "\n",
    "The performance measure is validation AUC. State this for the model in (b), and for each of the models here comment on whether it is better than the model in (b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - AUC: 0.7901 - loss: 0.3971 - val_AUC: 0.8895 - val_loss: 0.2327\n",
      "Epoch 2/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9015 - loss: 0.2241 - val_AUC: 0.9080 - val_loss: 0.2169\n",
      "Epoch 3/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - AUC: 0.9131 - loss: 0.2152 - val_AUC: 0.9036 - val_loss: 0.2213\n",
      "Epoch 4/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - AUC: 0.9155 - loss: 0.2088 - val_AUC: 0.9095 - val_loss: 0.2158\n",
      "Epoch 5/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - AUC: 0.9180 - loss: 0.2083 - val_AUC: 0.9119 - val_loss: 0.2156\n",
      "Epoch 6/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9247 - loss: 0.1988 - val_AUC: 0.9109 - val_loss: 0.2160\n",
      "Epoch 7/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9202 - loss: 0.2030 - val_AUC: 0.9139 - val_loss: 0.2132\n",
      "Epoch 8/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9280 - loss: 0.1937 - val_AUC: 0.9059 - val_loss: 0.2190\n",
      "Epoch 9/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9310 - loss: 0.1954 - val_AUC: 0.9051 - val_loss: 0.2210\n",
      "Epoch 10/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9382 - loss: 0.1842 - val_AUC: 0.9113 - val_loss: 0.2201\n",
      "Epoch 11/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9380 - loss: 0.1830 - val_AUC: 0.9126 - val_loss: 0.2183\n",
      "Epoch 12/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9423 - loss: 0.1802 - val_AUC: 0.9084 - val_loss: 0.2227\n",
      "Epoch 13/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9482 - loss: 0.1708 - val_AUC: 0.9025 - val_loss: 0.2294\n",
      "Epoch 14/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - AUC: 0.9450 - loss: 0.1717 - val_AUC: 0.9040 - val_loss: 0.2243\n",
      "Epoch 15/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - AUC: 0.9509 - loss: 0.1680 - val_AUC: 0.8998 - val_loss: 0.2351\n",
      "Epoch 16/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - AUC: 0.9514 - loss: 0.1669 - val_AUC: 0.8987 - val_loss: 0.2368\n",
      "Epoch 17/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9544 - loss: 0.1633 - val_AUC: 0.9005 - val_loss: 0.2433\n",
      "Epoch 18/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - AUC: 0.9564 - loss: 0.1548 - val_AUC: 0.8976 - val_loss: 0.2410\n",
      "Epoch 19/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - AUC: 0.9554 - loss: 0.1589 - val_AUC: 0.8888 - val_loss: 0.2550\n",
      "Epoch 20/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - AUC: 0.9576 - loss: 0.1546 - val_AUC: 0.8942 - val_loss: 0.2465\n",
      "Epoch 21/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - AUC: 0.9611 - loss: 0.1496 - val_AUC: 0.8887 - val_loss: 0.2564\n",
      "Epoch 22/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9604 - loss: 0.1513 - val_AUC: 0.8873 - val_loss: 0.2592\n",
      "Epoch 23/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9679 - loss: 0.1365 - val_AUC: 0.8932 - val_loss: 0.2503\n",
      "Epoch 24/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9639 - loss: 0.1440 - val_AUC: 0.8901 - val_loss: 0.2555\n",
      "Epoch 25/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9645 - loss: 0.1400 - val_AUC: 0.8833 - val_loss: 0.2756\n",
      "Epoch 26/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9674 - loss: 0.1366 - val_AUC: 0.8801 - val_loss: 0.2727\n",
      "Epoch 27/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9703 - loss: 0.1307 - val_AUC: 0.8808 - val_loss: 0.2762\n",
      "Epoch 28/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9698 - loss: 0.1348 - val_AUC: 0.8630 - val_loss: 0.2982\n",
      "Epoch 29/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9704 - loss: 0.1317 - val_AUC: 0.8731 - val_loss: 0.2898\n",
      "Epoch 30/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9722 - loss: 0.1285 - val_AUC: 0.8703 - val_loss: 0.2931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3e3634a50>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_session()\n",
    "model_batch = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train.shape[1:]),\n",
    "])\n",
    "\n",
    "for _ in range(4):\n",
    "    model_batch.add(tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer=\"he_normal\"))\n",
    "    model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model_batch.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model_batch.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"AUC\"])\n",
    "model_batch.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - AUC: 0.8412 - loss: 0.2695 - val_AUC: 0.9011 - val_loss: 0.2241\n",
      "Epoch 2/30\n",
      "\u001b[1m  9/817\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - AUC: 0.9513 - loss: 0.1757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: AUC,loss,val_AUC,val_loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - AUC: 0.9107 - loss: 0.2151 - val_AUC: 0.9062 - val_loss: 0.2190\n",
      "Epoch 3/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9177 - loss: 0.2081 - val_AUC: 0.9094 - val_loss: 0.2159\n",
      "Epoch 4/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9229 - loss: 0.2027 - val_AUC: 0.9106 - val_loss: 0.2148\n",
      "Epoch 5/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - AUC: 0.9275 - loss: 0.1976 - val_AUC: 0.9104 - val_loss: 0.2154\n",
      "Epoch 6/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - AUC: 0.9316 - loss: 0.1925 - val_AUC: 0.9084 - val_loss: 0.2175\n",
      "Epoch 7/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9358 - loss: 0.1872 - val_AUC: 0.9064 - val_loss: 0.2210\n",
      "Epoch 8/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9398 - loss: 0.1815 - val_AUC: 0.9037 - val_loss: 0.2258\n",
      "Epoch 9/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9442 - loss: 0.1752 - val_AUC: 0.9017 - val_loss: 0.2314\n",
      "Epoch 10/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9487 - loss: 0.1683 - val_AUC: 0.8993 - val_loss: 0.2391\n",
      "Epoch 11/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9529 - loss: 0.1604 - val_AUC: 0.8970 - val_loss: 0.2489\n",
      "Epoch 12/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9578 - loss: 0.1517 - val_AUC: 0.8931 - val_loss: 0.2636\n",
      "Epoch 13/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9624 - loss: 0.1425 - val_AUC: 0.8861 - val_loss: 0.2822\n",
      "Epoch 14/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9669 - loss: 0.1335 - val_AUC: 0.8819 - val_loss: 0.2987\n",
      "Epoch 15/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9712 - loss: 0.1258 - val_AUC: 0.8795 - val_loss: 0.3162\n",
      "Epoch 16/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9747 - loss: 0.1184 - val_AUC: 0.8720 - val_loss: 0.3310\n",
      "Epoch 17/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - AUC: 0.9787 - loss: 0.1083 - val_AUC: 0.8702 - val_loss: 0.3657\n",
      "Epoch 18/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9818 - loss: 0.1011 - val_AUC: 0.8595 - val_loss: 0.3951\n",
      "Epoch 19/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9859 - loss: 0.0892 - val_AUC: 0.8549 - val_loss: 0.4227\n",
      "Epoch 20/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - AUC: 0.9887 - loss: 0.0800 - val_AUC: 0.8494 - val_loss: 0.4780\n",
      "Epoch 21/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - AUC: 0.9912 - loss: 0.0716 - val_AUC: 0.8513 - val_loss: 0.4974\n",
      "Epoch 22/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9903 - loss: 0.0722 - val_AUC: 0.8407 - val_loss: 0.5278\n",
      "Epoch 23/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - AUC: 0.9931 - loss: 0.0639 - val_AUC: 0.8415 - val_loss: 0.5175\n",
      "Epoch 24/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9925 - loss: 0.0626 - val_AUC: 0.8322 - val_loss: 0.5836\n",
      "Epoch 25/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - AUC: 0.9941 - loss: 0.0552 - val_AUC: 0.8351 - val_loss: 0.6016\n",
      "Epoch 26/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9945 - loss: 0.0557 - val_AUC: 0.8186 - val_loss: 0.5869\n",
      "Epoch 27/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9955 - loss: 0.0511 - val_AUC: 0.8238 - val_loss: 0.6463\n",
      "Epoch 28/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9959 - loss: 0.0446 - val_AUC: 0.8235 - val_loss: 0.6689\n",
      "Epoch 29/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9962 - loss: 0.0443 - val_AUC: 0.8176 - val_loss: 0.6893\n",
      "Epoch 30/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9969 - loss: 0.0422 - val_AUC: 0.8175 - val_loss: 0.6744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3b230bed0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_session()\n",
    "model_es = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train.shape[1:]),\n",
    "])\n",
    "\n",
    "for _ in range(4):\n",
    "    model_es.add(tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer=\"he_normal\"))\n",
    "\n",
    "model_es.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_es.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"AUC\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=10,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "model_es.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii) l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 18ms/step - AUC: 0.8400 - loss: 0.4149 - val_AUC: 0.9029 - val_loss: 0.3208\n",
      "Epoch 2/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9080 - loss: 0.3052 - val_AUC: 0.9069 - val_loss: 0.2829\n",
      "Epoch 3/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9131 - loss: 0.2719 - val_AUC: 0.9097 - val_loss: 0.2619\n",
      "Epoch 4/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9162 - loss: 0.2528 - val_AUC: 0.9111 - val_loss: 0.2499\n",
      "Epoch 5/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9181 - loss: 0.2412 - val_AUC: 0.9120 - val_loss: 0.2425\n",
      "Epoch 6/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9197 - loss: 0.2339 - val_AUC: 0.9126 - val_loss: 0.2376\n",
      "Epoch 7/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9210 - loss: 0.2289 - val_AUC: 0.9135 - val_loss: 0.2341\n",
      "Epoch 8/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9222 - loss: 0.2253 - val_AUC: 0.9143 - val_loss: 0.2315\n",
      "Epoch 9/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9230 - loss: 0.2226 - val_AUC: 0.9148 - val_loss: 0.2295\n",
      "Epoch 10/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9240 - loss: 0.2204 - val_AUC: 0.9155 - val_loss: 0.2280\n",
      "Epoch 11/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9250 - loss: 0.2186 - val_AUC: 0.9160 - val_loss: 0.2267\n",
      "Epoch 12/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9259 - loss: 0.2171 - val_AUC: 0.9162 - val_loss: 0.2257\n",
      "Epoch 13/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9266 - loss: 0.2158 - val_AUC: 0.9165 - val_loss: 0.2248\n",
      "Epoch 14/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9272 - loss: 0.2147 - val_AUC: 0.9171 - val_loss: 0.2241\n",
      "Epoch 15/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9279 - loss: 0.2138 - val_AUC: 0.9174 - val_loss: 0.2235\n",
      "Epoch 16/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9285 - loss: 0.2130 - val_AUC: 0.9174 - val_loss: 0.2230\n",
      "Epoch 17/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9289 - loss: 0.2122 - val_AUC: 0.9177 - val_loss: 0.2226\n",
      "Epoch 18/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9295 - loss: 0.2115 - val_AUC: 0.9180 - val_loss: 0.2222\n",
      "Epoch 19/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9298 - loss: 0.2109 - val_AUC: 0.9182 - val_loss: 0.2219\n",
      "Epoch 20/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9304 - loss: 0.2103 - val_AUC: 0.9184 - val_loss: 0.2217\n",
      "Epoch 21/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9308 - loss: 0.2098 - val_AUC: 0.9183 - val_loss: 0.2215\n",
      "Epoch 22/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9311 - loss: 0.2093 - val_AUC: 0.9184 - val_loss: 0.2214\n",
      "Epoch 23/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9316 - loss: 0.2088 - val_AUC: 0.9183 - val_loss: 0.2212\n",
      "Epoch 24/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9319 - loss: 0.2083 - val_AUC: 0.9183 - val_loss: 0.2212\n",
      "Epoch 25/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9323 - loss: 0.2079 - val_AUC: 0.9184 - val_loss: 0.2210\n",
      "Epoch 26/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9327 - loss: 0.2075 - val_AUC: 0.9189 - val_loss: 0.2210\n",
      "Epoch 27/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9330 - loss: 0.2071 - val_AUC: 0.9188 - val_loss: 0.2209\n",
      "Epoch 28/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9330 - loss: 0.2068 - val_AUC: 0.9192 - val_loss: 0.2208\n",
      "Epoch 29/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9333 - loss: 0.2065 - val_AUC: 0.9190 - val_loss: 0.2208\n",
      "Epoch 30/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9334 - loss: 0.2062 - val_AUC: 0.9192 - val_loss: 0.2208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x46b3fe5d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_session()\n",
    "model_l2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train.shape[1:]),\n",
    "])\n",
    "\n",
    "for _ in range(4):\n",
    "    model_l2.add(tf.keras.layers.Dense(\n",
    "        100, \n",
    "        activation=\"swish\", \n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.0002)\n",
    "    ))\n",
    "\n",
    "model_l2.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model_l2.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"AUC\"])\n",
    "model_l2.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iv) dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 18ms/step - AUC: 0.8415 - loss: 0.2669 - val_AUC: 0.9010 - val_loss: 0.2238\n",
      "Epoch 2/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9103 - loss: 0.2157 - val_AUC: 0.9068 - val_loss: 0.2190\n",
      "Epoch 3/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9180 - loss: 0.2078 - val_AUC: 0.9121 - val_loss: 0.2135\n",
      "Epoch 4/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9232 - loss: 0.2021 - val_AUC: 0.9145 - val_loss: 0.2110\n",
      "Epoch 5/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9270 - loss: 0.1981 - val_AUC: 0.9148 - val_loss: 0.2106\n",
      "Epoch 6/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9308 - loss: 0.1938 - val_AUC: 0.9143 - val_loss: 0.2107\n",
      "Epoch 7/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9327 - loss: 0.1908 - val_AUC: 0.9144 - val_loss: 0.2107\n",
      "Epoch 8/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9370 - loss: 0.1855 - val_AUC: 0.9130 - val_loss: 0.2133\n",
      "Epoch 9/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9387 - loss: 0.1825 - val_AUC: 0.9133 - val_loss: 0.2164\n",
      "Epoch 10/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9421 - loss: 0.1773 - val_AUC: 0.9105 - val_loss: 0.2204\n",
      "Epoch 11/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9461 - loss: 0.1725 - val_AUC: 0.9069 - val_loss: 0.2271\n",
      "Epoch 12/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9487 - loss: 0.1684 - val_AUC: 0.9034 - val_loss: 0.2335\n",
      "Epoch 13/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9510 - loss: 0.1646 - val_AUC: 0.9007 - val_loss: 0.2392\n",
      "Epoch 14/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9542 - loss: 0.1592 - val_AUC: 0.9001 - val_loss: 0.2527\n",
      "Epoch 15/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9578 - loss: 0.1534 - val_AUC: 0.8950 - val_loss: 0.2558\n",
      "Epoch 16/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9611 - loss: 0.1478 - val_AUC: 0.8927 - val_loss: 0.2665\n",
      "Epoch 17/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9648 - loss: 0.1407 - val_AUC: 0.8890 - val_loss: 0.2693\n",
      "Epoch 18/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9667 - loss: 0.1369 - val_AUC: 0.8861 - val_loss: 0.2853\n",
      "Epoch 19/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9695 - loss: 0.1313 - val_AUC: 0.8826 - val_loss: 0.2964\n",
      "Epoch 20/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9713 - loss: 0.1271 - val_AUC: 0.8755 - val_loss: 0.3159\n",
      "Epoch 21/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9730 - loss: 0.1227 - val_AUC: 0.8774 - val_loss: 0.3209\n",
      "Epoch 22/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9753 - loss: 0.1174 - val_AUC: 0.8639 - val_loss: 0.3320\n",
      "Epoch 23/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9772 - loss: 0.1140 - val_AUC: 0.8647 - val_loss: 0.3416\n",
      "Epoch 24/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - AUC: 0.9789 - loss: 0.1087 - val_AUC: 0.8651 - val_loss: 0.3505\n",
      "Epoch 25/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9822 - loss: 0.1011 - val_AUC: 0.8581 - val_loss: 0.3699\n",
      "Epoch 26/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9835 - loss: 0.0982 - val_AUC: 0.8594 - val_loss: 0.3726\n",
      "Epoch 27/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - AUC: 0.9847 - loss: 0.0943 - val_AUC: 0.8451 - val_loss: 0.3929\n",
      "Epoch 28/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - AUC: 0.9847 - loss: 0.0937 - val_AUC: 0.8466 - val_loss: 0.3978\n",
      "Epoch 29/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9873 - loss: 0.0859 - val_AUC: 0.8448 - val_loss: 0.4094\n",
      "Epoch 30/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9867 - loss: 0.0871 - val_AUC: 0.8416 - val_loss: 0.4230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x46d4e4a50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_session()\n",
    "model_dropout = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train.shape[1:]),\n",
    "])\n",
    "\n",
    "for _ in range(4):\n",
    "    model_dropout.add(tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer=\"he_normal\"))\n",
    "    model_dropout.add(tf.keras.layers.Dropout(0.02))\n",
    "\n",
    "model_dropout.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model_dropout.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"AUC\"])\n",
    "model_dropout.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(v) L2 + Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 17ms/step - AUC: 0.8490 - loss: 0.4039 - val_AUC: 0.9027 - val_loss: 0.3205\n",
      "Epoch 2/30\n",
      "\u001b[1m  9/817\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - AUC: 0.9536 - loss: 0.2677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terencechiu/Documents/CFRM421/.venv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: AUC,loss,val_AUC,val_loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9096 - loss: 0.3044 - val_AUC: 0.9076 - val_loss: 0.2822\n",
      "Epoch 3/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9146 - loss: 0.2711 - val_AUC: 0.9106 - val_loss: 0.2606\n",
      "Epoch 4/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9173 - loss: 0.2518 - val_AUC: 0.9128 - val_loss: 0.2478\n",
      "Epoch 5/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9192 - loss: 0.2403 - val_AUC: 0.9142 - val_loss: 0.2398\n",
      "Epoch 6/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9205 - loss: 0.2332 - val_AUC: 0.9155 - val_loss: 0.2346\n",
      "Epoch 7/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9219 - loss: 0.2285 - val_AUC: 0.9162 - val_loss: 0.2311\n",
      "Epoch 8/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9227 - loss: 0.2252 - val_AUC: 0.9168 - val_loss: 0.2285\n",
      "Epoch 9/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9234 - loss: 0.2227 - val_AUC: 0.9176 - val_loss: 0.2267\n",
      "Epoch 10/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9241 - loss: 0.2207 - val_AUC: 0.9177 - val_loss: 0.2253\n",
      "Epoch 11/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9246 - loss: 0.2191 - val_AUC: 0.9177 - val_loss: 0.2241\n",
      "Epoch 12/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9252 - loss: 0.2178 - val_AUC: 0.9179 - val_loss: 0.2232\n",
      "Epoch 13/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9258 - loss: 0.2166 - val_AUC: 0.9182 - val_loss: 0.2224\n",
      "Epoch 14/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9264 - loss: 0.2155 - val_AUC: 0.9185 - val_loss: 0.2218\n",
      "Epoch 15/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9269 - loss: 0.2146 - val_AUC: 0.9189 - val_loss: 0.2212\n",
      "Epoch 16/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9275 - loss: 0.2137 - val_AUC: 0.9189 - val_loss: 0.2208\n",
      "Epoch 17/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9279 - loss: 0.2129 - val_AUC: 0.9188 - val_loss: 0.2204\n",
      "Epoch 18/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9282 - loss: 0.2122 - val_AUC: 0.9190 - val_loss: 0.2200\n",
      "Epoch 19/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9286 - loss: 0.2116 - val_AUC: 0.9192 - val_loss: 0.2196\n",
      "Epoch 20/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9290 - loss: 0.2110 - val_AUC: 0.9195 - val_loss: 0.2193\n",
      "Epoch 21/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9293 - loss: 0.2105 - val_AUC: 0.9197 - val_loss: 0.2191\n",
      "Epoch 22/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9298 - loss: 0.2100 - val_AUC: 0.9198 - val_loss: 0.2187\n",
      "Epoch 23/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9303 - loss: 0.2094 - val_AUC: 0.9199 - val_loss: 0.2184\n",
      "Epoch 24/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9306 - loss: 0.2090 - val_AUC: 0.9202 - val_loss: 0.2182\n",
      "Epoch 25/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - AUC: 0.9308 - loss: 0.2086 - val_AUC: 0.9205 - val_loss: 0.2181\n",
      "Epoch 26/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9312 - loss: 0.2082 - val_AUC: 0.9206 - val_loss: 0.2179\n",
      "Epoch 27/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 18ms/step - AUC: 0.9315 - loss: 0.2078 - val_AUC: 0.9209 - val_loss: 0.2177\n",
      "Epoch 28/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - AUC: 0.9319 - loss: 0.2075 - val_AUC: 0.9205 - val_loss: 0.2177\n",
      "Epoch 29/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - AUC: 0.9320 - loss: 0.2071 - val_AUC: 0.9204 - val_loss: 0.2174\n",
      "Epoch 30/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - AUC: 0.9323 - loss: 0.2067 - val_AUC: 0.9205 - val_loss: 0.2173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x471d44a50>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_session()\n",
    "model_l2_es = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train.shape[1:]),\n",
    "])\n",
    "\n",
    "for _ in range(4):\n",
    "    model_l2_es.add(tf.keras.layers.Dense(\n",
    "        100, \n",
    "        activation=\"swish\", \n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.0002)\n",
    "    ))\n",
    "\n",
    "model_l2_es.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model_l2_es.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"AUC\"])\n",
    "model_l2_es.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(vi) Batch Normalization + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - AUC: 0.7886 - loss: 0.3987 - val_AUC: 0.8883 - val_loss: 0.2355\n",
      "Epoch 2/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9030 - loss: 0.2239 - val_AUC: 0.8973 - val_loss: 0.2296\n",
      "Epoch 3/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - AUC: 0.9182 - loss: 0.2082 - val_AUC: 0.8966 - val_loss: 0.2316\n",
      "Epoch 4/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9276 - loss: 0.1974 - val_AUC: 0.8927 - val_loss: 0.2413\n",
      "Epoch 5/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9353 - loss: 0.1881 - val_AUC: 0.8954 - val_loss: 0.2421\n",
      "Epoch 6/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - AUC: 0.9431 - loss: 0.1776 - val_AUC: 0.8906 - val_loss: 0.2516\n",
      "Epoch 7/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - AUC: 0.9491 - loss: 0.1684 - val_AUC: 0.8871 - val_loss: 0.2597\n",
      "Epoch 8/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - AUC: 0.9563 - loss: 0.1569 - val_AUC: 0.8842 - val_loss: 0.2666\n",
      "Epoch 9/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - AUC: 0.9619 - loss: 0.1480 - val_AUC: 0.8786 - val_loss: 0.2821\n",
      "Epoch 10/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9685 - loss: 0.1352 - val_AUC: 0.8758 - val_loss: 0.2954\n",
      "Epoch 11/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9735 - loss: 0.1242 - val_AUC: 0.8640 - val_loss: 0.3181\n",
      "Epoch 12/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9768 - loss: 0.1155 - val_AUC: 0.8637 - val_loss: 0.3238\n",
      "Epoch 13/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9808 - loss: 0.1061 - val_AUC: 0.8555 - val_loss: 0.3515\n",
      "Epoch 14/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9824 - loss: 0.1017 - val_AUC: 0.8468 - val_loss: 0.3620\n",
      "Epoch 15/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9845 - loss: 0.0938 - val_AUC: 0.8403 - val_loss: 0.3811\n",
      "Epoch 16/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 30ms/step - AUC: 0.9852 - loss: 0.0899 - val_AUC: 0.8413 - val_loss: 0.4053\n",
      "Epoch 17/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - AUC: 0.9880 - loss: 0.0830 - val_AUC: 0.8265 - val_loss: 0.4129\n",
      "Epoch 18/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - AUC: 0.9892 - loss: 0.0786 - val_AUC: 0.8289 - val_loss: 0.4265\n",
      "Epoch 19/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - AUC: 0.9903 - loss: 0.0714 - val_AUC: 0.8264 - val_loss: 0.4317\n",
      "Epoch 20/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - AUC: 0.9906 - loss: 0.0727 - val_AUC: 0.8231 - val_loss: 0.4477\n",
      "Epoch 21/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - AUC: 0.9930 - loss: 0.0644 - val_AUC: 0.8187 - val_loss: 0.4608\n",
      "Epoch 22/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9934 - loss: 0.0626 - val_AUC: 0.8203 - val_loss: 0.4660\n",
      "Epoch 23/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - AUC: 0.9911 - loss: 0.0674 - val_AUC: 0.8115 - val_loss: 0.4865\n",
      "Epoch 24/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - AUC: 0.9946 - loss: 0.0570 - val_AUC: 0.8181 - val_loss: 0.5047\n",
      "Epoch 25/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - AUC: 0.9932 - loss: 0.0592 - val_AUC: 0.8191 - val_loss: 0.4913\n",
      "Epoch 26/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - AUC: 0.9942 - loss: 0.0598 - val_AUC: 0.8074 - val_loss: 0.4982\n",
      "Epoch 27/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - AUC: 0.9931 - loss: 0.0573 - val_AUC: 0.8063 - val_loss: 0.5139\n",
      "Epoch 28/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - AUC: 0.9944 - loss: 0.0512 - val_AUC: 0.8052 - val_loss: 0.5202\n",
      "Epoch 29/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - AUC: 0.9952 - loss: 0.0508 - val_AUC: 0.8087 - val_loss: 0.5319\n",
      "Epoch 30/30\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - AUC: 0.9943 - loss: 0.0533 - val_AUC: 0.7885 - val_loss: 0.5650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x48aa60f50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_session()\n",
    "model_bn_dropout = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(input_shape=X_train.shape[1:]),\n",
    "])\n",
    "\n",
    "for _ in range(4):\n",
    "    model_bn_dropout.add(tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer=\"he_normal\"))\n",
    "    model_bn_dropout.add(tf.keras.layers.BatchNormalization())\n",
    "    model_bn_dropout.add(tf.keras.layers.Dropout(0.02))\n",
    "\n",
    "model_bn_dropout.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model_bn_dropout.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"AUC\"])\n",
    "model_bn_dropout.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) [1 mark]\n",
    "\n",
    "For the dropout model in (c)(iv) determine whether or not it is overfitting less than the model in (b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) [1 mark]\n",
    "\n",
    "Of the models in (b) and (c), one would now choose the best model according to the performance metric (validation AUC) to evaluate on the test set. But instead, evaluate the model in (c)(v) on the test set in terms of the AUC and confusion matrix (regardless of whether it is the best model given your results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Time series using machine learning [14 marks]\n",
    "\n",
    "Obtain daily values of the [Japan/U.S. Foreign Exchange Rate (DEXJPUS)](https://fred.stlouisfed.org/series/DEXJPUS) starting from Jan 1, 1990, to Jan 1, 2023, from FRED. This can be obtained using the code below or you can download the data as a csv file from [Canvas](https://canvas.uw.edu/files/106328118/download?download_frd=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "from datetime import datetime\n",
    "data = pdr.get_data_fred('DEXJPUS', datetime(1990,1,1),datetime(2023,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [2 marks]\n",
    "\n",
    "Create a training set (before 2010), a validation set (Jan 2010 to Dec 2015), and a test set (the rest of the data). Turn the time series data into a supervised learning dataset where the features are the value of the exchange rate in the last 10 days inclusive of the current day, and the target is the value of the exchange rate in the next day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data.index < '2010-01-01']\n",
    "val_data = data[(data.index >= '2010-01-01') & (data.index < '2016-01-01')]\n",
    "test_data = data[data.index >= '2016-01-01']\n",
    "\n",
    "def create_supervised_dataset(data, window_size=10):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data.iloc[i:i+window_size].values)\n",
    "        y.append(data.iloc[i+window_size].values[0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_supervised_dataset(train_data)\n",
    "X_val, y_val = create_supervised_dataset(val_data)\n",
    "X_test, y_test = create_supervised_dataset(test_data)\n",
    "\n",
    "print(\"Training set shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shapes:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shapes:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [3 marks]\n",
    "\n",
    "Fit a random forest regressor to predict the value of the exchange rate in the next day. Using the test set, report the mean squared error and the accuracy for the movement direction.\n",
    "\n",
    "Hint: You can calculate the accuracy of the movement direction by determining what the actual movement direction is and comparing it to the movement direction corresponding to the predicted value of the exchange rate. For instance, the movement direction of the test set `X_test` and `y_test` where a strictly up movement is `True` can be computed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_test = X_test[:,-1] < y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "movement_pred = X_test[:,-1] < y_pred.ravel()  # Predicted movement\n",
    "\n",
    "# Accuracy\n",
    "movement_accuracy = (movement_test == movement_pred).mean()\n",
    "print(f\"Movement Direction Accuracy: {movement_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) [4 marks]\n",
    "\n",
    "Repeat (b), but now fit a deep RNN with 2 recurrent layers of 20 and 20 neurons, and an output layer which is 1 dense neuron. Use 100 epochs and the Nadam optimizer. Comment on the result and the learning curve (the validation set is used for the learning curve)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_session()\n",
    "\n",
    "model_rnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(20, input_shape=[None,1], return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_rnn.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "\n",
    "history = model_rnn.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = model_rnn.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"\\nTest MSE: {mse:.4f}\")\n",
    "\n",
    "# Calculate movement direction accuracy\n",
    "movement_test = X_test[:,-1] < y_test.ravel()\n",
    "movement_pred = X_test[:,-1] < y_pred.ravel()\n",
    "movement_accuracy = (movement_test == movement_pred).mean()\n",
    "print(f\"Movement Direction Accuracy: {movement_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) [5 marks]\n",
    "\n",
    "Create a supervised learning dataset suitable for predicting 3 days ahead instead of 1 day ahead. Adjust the deep RNN in (c) so that it predicts 3 days ahead. Use 100 epochs and the Nadam optimizer. Using the test set, report the mean squared error and the accuracy for the movement direction for each of the 3 days ahead predictions.  Comment on the result and the learning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_supervised_dataset_3days(data, window_size=10):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(data) - window_size - 2):  # -2 to account for 3 days ahead\n",
    "        # Get the window of 10 days (including current day)\n",
    "        X.append(data.iloc[i:i+window_size].values)\n",
    "        # Get the next 3 days' values as targets\n",
    "        y.append(data.iloc[i+window_size:i+window_size+3].values)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train_3days, y_train_3days = create_supervised_dataset_3days(train_data)\n",
    "X_val_3days, y_val_3days = create_supervised_dataset_3days(val_data)\n",
    "X_test_3days, y_test_3days = create_supervised_dataset_3days(test_data)\n",
    "\n",
    "reset_session()\n",
    "\n",
    "model_rnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(20, input_shape=[None,1], return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])\n",
    "\n",
    "model_rnn.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "\n",
    "history = model_rnn.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "for day in range(3):\n",
    "    # MSE\n",
    "    mse = mean_squared_error(y_test[:, day], y_pred[:, day])\n",
    "    print(f\"\\nDay {day+1} ahead:\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    \n",
    "    # Calculate movement direction accuracy\n",
    "    current_rates = X_test[:, -1, 0]  # Last known rate\n",
    "    actual_movement = current_rates < y_test[:, day]\n",
    "    predicted_movement = current_rates < y_pred[:, day]\n",
    "    movement_accuracy = (actual_movement == predicted_movement).mean()\n",
    "    print(f\"Movement Direction Accuracy: {movement_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
